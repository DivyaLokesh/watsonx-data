{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Step 0\n","\n","## - Click on the menu to the right\n","\n","## - \"Insert Project Token\"\n","\n","## - Use the downward arrow icon on the top menu to move the cell down and begin running the notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"cfa55044-e7e0-4e80-b65d-27433b7dfad2","msg_id":"4b05e1ba-4568-43f2-bb46-587adc1ec350"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Load Data into Milvus for RAG\n","\n","\n","# 1. Set up the environment\n","\n","## Install libraries\n","\n","we need to install the pymilvus package to the watsonx.ai Python environment. "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"18d833d6-d74f-4692-a764-4fcf2ceefe17","msg_id":"e58f09cf-706b-4905-bbe4-59d44a53b484"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: grpcio==1.60.0 in ./python/lib/python/site-packages (1.60.0)\n","Requirement already satisfied: pymilvus in ./python/lib/python/site-packages (2.5.0)\n","Requirement already satisfied: setuptools>69 in ./python/lib/python/site-packages (from pymilvus) (72.1.0)\n","Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in ./python/lib/python/site-packages (from pymilvus) (1.60.0)\n","Requirement already satisfied: protobuf>=3.20.0 in ./python/lib/python/site-packages (from pymilvus) (4.21.12)\n","Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in ./python/lib/python/site-packages (from pymilvus) (1.0.1)\n","Requirement already satisfied: ujson>=2.0.0 in ./python/lib/python/site-packages (from pymilvus) (5.10.0)\n","Requirement already satisfied: pandas>=1.2.4 in ./python/lib/python/site-packages (from pymilvus) (2.1.4)\n","Requirement already satisfied: milvus-lite>=2.4.0 in ./python/lib/python/site-packages (from pymilvus) (2.4.10)\n","Requirement already satisfied: tqdm in ./python/lib/python/site-packages (from milvus-lite>=2.4.0->pymilvus) (4.65.0)\n","Requirement already satisfied: numpy<2,>=1.23.2 in ./python/lib/python/site-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in ./python/lib/python/site-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in ./python/lib/python/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in ./python/lib/python/site-packages (from pandas>=1.2.4->pymilvus) (2023.3)\n","Requirement already satisfied: six>=1.5 in ./python/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n"]}],"source":["!pip install grpcio==1.60.0 \n","!pip install pymilvus"]},{"cell_type":"markdown","metadata":{},"source":["# !!RESTART THE KERNAL AFTER pymilvus install!! \n","\n","Certain dependencies need to be persisted. Restarting the kernal allows this to occur"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0a8b9b47-22fe-4a70-8d1a-78b635a986a6","msg_id":"ed02aa17-c355-4096-a52d-6400e868c53a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ipython-sql==0.4.1 in ./python/lib/python/site-packages (0.4.1)\n","Requirement already satisfied: prettytable<1 in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (0.7.2)\n","Requirement already satisfied: ipython>=1.0 in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (8.20.0)\n","Requirement already satisfied: sqlalchemy>=0.6.7 in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (1.4.46)\n","Requirement already satisfied: sqlparse in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (0.5.2)\n","Requirement already satisfied: six in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (1.16.0)\n","Requirement already satisfied: ipython-genutils>=0.1.0 in ./python/lib/python/site-packages (from ipython-sql==0.4.1) (0.2.0)\n","Requirement already satisfied: decorator in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.6)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (3.0.43)\n","Requirement already satisfied: pygments>=2.4.0 in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (2.15.1)\n","Requirement already satisfied: stack-data in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\n","Requirement already satisfied: traitlets>=5 in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.7.1)\n","Requirement already satisfied: pexpect>4.3 in ./python/lib/python/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.8.0)\n","Requirement already satisfied: greenlet!=0.4.17 in ./python/lib/python/site-packages (from sqlalchemy>=0.6.7->ipython-sql==0.4.1) (3.0.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./python/lib/python/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql==0.4.1) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in ./python/lib/python/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql==0.4.1) (0.7.0)\n","Requirement already satisfied: wcwidth in ./python/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=1.0->ipython-sql==0.4.1) (0.2.5)\n","Requirement already satisfied: executing in ./python/lib/python/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (0.8.3)\n","Requirement already satisfied: asttokens in ./python/lib/python/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (2.0.5)\n","Requirement already satisfied: pure-eval in ./python/lib/python/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (0.2.2)\n","Requirement already satisfied: sqlalchemy==1.4.46 in ./python/lib/python/site-packages (1.4.46)\n","Requirement already satisfied: greenlet!=0.4.17 in ./python/lib/python/site-packages (from sqlalchemy==1.4.46) (3.0.1)\n","Requirement already satisfied: sqlalchemy==1.4.46 in ./python/lib/python/site-packages (1.4.46)\n","Requirement already satisfied: pyhive[presto] in ./python/lib/python/site-packages (0.7.0)\n","Requirement already satisfied: greenlet!=0.4.17 in ./python/lib/python/site-packages (from sqlalchemy==1.4.46) (3.0.1)\n","Requirement already satisfied: future in ./python/lib/python/site-packages (from pyhive[presto]) (0.18.3)\n","Requirement already satisfied: python-dateutil in ./python/lib/python/site-packages (from pyhive[presto]) (2.8.2)\n","Requirement already satisfied: requests>=1.0.0 in ./python/lib/python/site-packages (from pyhive[presto]) (2.32.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./python/lib/python/site-packages (from requests>=1.0.0->pyhive[presto]) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in ./python/lib/python/site-packages (from requests>=1.0.0->pyhive[presto]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./python/lib/python/site-packages (from requests>=1.0.0->pyhive[presto]) (1.26.19)\n","Requirement already satisfied: certifi>=2017.4.17 in ./python/lib/python/site-packages (from requests>=1.0.0->pyhive[presto]) (2023.7.22)\n","Requirement already satisfied: six>=1.5 in ./python/lib/python/site-packages (from python-dateutil->pyhive[presto]) (1.16.0)\n","Requirement already satisfied: python-dotenv in ./python/lib/python/site-packages (1.0.1)\n","Requirement already satisfied: sentence_transformers in ./python/lib/python/site-packages (3.3.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./python/lib/python/site-packages (from sentence_transformers) (4.47.0)\n","Requirement already satisfied: tqdm in ./python/lib/python/site-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.11.0 in ./python/lib/python/site-packages (from sentence_transformers) (2.1.2)\n","Requirement already satisfied: scikit-learn in ./python/lib/python/site-packages (from sentence_transformers) (1.3.0)\n","Requirement already satisfied: scipy in ./python/lib/python/site-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in ./python/lib/python/site-packages (from sentence_transformers) (0.27.0)\n","Requirement already satisfied: Pillow in ./python/lib/python/site-packages (from sentence_transformers) (10.3.0)\n","Requirement already satisfied: filelock in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2023.10.0)\n","Requirement already satisfied: packaging>=20.9 in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n","Requirement already satisfied: requests in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in ./python/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n","Requirement already satisfied: sympy in ./python/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in ./python/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (2.8.4)\n","Requirement already satisfied: jinja2 in ./python/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n","Requirement already satisfied: numpy>=1.17 in ./python/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in ./python/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in ./python/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in ./python/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n","Requirement already satisfied: joblib>=1.1.1 in ./python/lib/python/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in ./python/lib/python/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./python/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./python/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in ./python/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./python/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.19)\n","Requirement already satisfied: certifi>=2017.4.17 in ./python/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in ./python/lib/python/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: langchain-community in ./python/lib/python/site-packages (0.3.12)\n","Requirement already satisfied: PyYAML>=5.3 in ./python/lib/python/site-packages (from langchain-community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./python/lib/python/site-packages (from langchain-community) (1.4.46)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./python/lib/python/site-packages (from langchain-community) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./python/lib/python/site-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./python/lib/python/site-packages (from langchain-community) (0.4.0)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.12 in ./python/lib/python/site-packages (from langchain-community) (0.3.12)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in ./python/lib/python/site-packages (from langchain-community) (0.3.25)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in ./python/lib/python/site-packages (from langchain-community) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in ./python/lib/python/site-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./python/lib/python/site-packages (from langchain-community) (2.7.0)\n","Requirement already satisfied: requests<3,>=2 in ./python/lib/python/site-packages (from langchain-community) (2.32.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./python/lib/python/site-packages (from langchain-community) (8.2.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in ./python/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in ./python/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in ./python/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in ./python/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in ./python/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./python/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./python/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./python/lib/python/site-packages (from langchain<0.4.0,>=0.3.12->langchain-community) (0.3.3)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./python/lib/python/site-packages (from langchain<0.4.0,>=0.3.12->langchain-community) (2.10.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./python/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in ./python/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (23.2)\n","Requirement already satisfied: typing-extensions>=4.7 in ./python/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in ./python/lib/python/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.26.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./python/lib/python/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./python/lib/python/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in ./python/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./python/lib/python/site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in ./python/lib/python/site-packages (from requests<3,>=2->langchain-community) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./python/lib/python/site-packages (from requests<3,>=2->langchain-community) (1.26.19)\n","Requirement already satisfied: certifi>=2017.4.17 in ./python/lib/python/site-packages (from requests<3,>=2->langchain-community) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in ./python/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n","Requirement already satisfied: anyio in ./python/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.5.0)\n","Requirement already satisfied: httpcore==1.* in ./python/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.2)\n","Requirement already satisfied: sniffio in ./python/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in ./python/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in ./python/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain-community) (2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in ./python/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain-community) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in ./python/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain-community) (2.27.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in ./python/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Requirement already satisfied: PyMuPDF in ./python/lib/python/site-packages (1.25.1)\n"]}],"source":["!pip install ipython-sql==0.4.1\n","!pip install sqlalchemy==1.4.46\n","!pip install sqlalchemy==1.4.46 \"pyhive[presto]\"\n","!pip install python-dotenv\n","!pip install sentence_transformers\n","!pip install langchain-community\n","!pip install PyMuPDF\n","\n","# clean up the libraries not required"]},{"cell_type":"markdown","metadata":{},"source":["# Step 1: Document Ingestion\n","\n","## Load the pdf version of the watsonx.data documentation\n","\n","Load the pdf version as an asset in the project using Spark"]},{"cell_type":"code","execution_count":4,"metadata":{"msg_id":"978e99a2-57df-465c-ad8b-a6df6194849f"},"outputs":[{"name":"stdout","output_type":"stream","text":["PDF downloaded successfully to wxd_doc_pdf.pdf\n"]}],"source":["import requests\n","from pyspark.sql import SparkSession\n","import os\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Download watsonx.data PDF documentation\") \\\n","    .getOrCreate()\n","\n","def download_pdf(url, local_path):\n","    \"\"\"Download the PDF from a URL and save it locally\"\"\"\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        with open(local_path, 'wb') as file:\n","            file.write(response.content)\n","        print(f\"PDF downloaded successfully to {local_path}\")\n","    else:\n","        print(f\"Failed to download PDF. Status code: {response.status_code}\")\n","\n","pdf_url = \"https://www.ibm.com/support/pages/system/files/inline-files/IBM%20watsonx.data%20version%202.0.3.pdf\"  \n","local_file_path = \"wxd_doc_pdf.pdf\"  \n","\n","download_pdf(pdf_url, local_file_path)\n","\n","spark.stop()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Code to extract the text from the pdf for embeddings"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"a16b9680-5689-4203-82b9-db682c6e8bfb","msg_id":"0cd62522-5f5e-452c-a766-abdcedec4685"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'name': 'wxd_doc_pdf', 'description': None, 'asset_id': '1377b784-7528-4933-ade1-096dafbf2d7a', 'asset_type': 'data_asset', 'tags': None}]\n"]}],"source":["\n","# from langchain_community.document_loaders import DirectoryLoader\n","# from langchain_community.document_loaders import PyPDFLoader\n","\n","asset_li=wslib.assets.list_assets(\"data_asset\")\n","print(asset_li)\n","\n","wslib.download_file(\"wxd_doc_pdf\")\n","\n","import fitz # PyMuPDF\n","\n","doc = fitz.open(\"wxd_doc_pdf\")\n","\n","pdf_text = \"\"\n","\n","for page in doc:\n","    pdf_text += page.get_text()\n","\n","# print(pdf_text)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Document Chunking\n","\n","To manage the large texts, we can divide the data into manageble chunks by logical units such as paragraphs, sentences, or fixed token lengths"]},{"cell_type":"markdown","metadata":{},"source":["### Option 1: Chunking by Paragraphs"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"12022d7e-0129-4493-9099-78b4a25ebce9","msg_id":"f3b4025e-8b94-4162-bd61-a660ed461c70"},"outputs":[],"source":["def chunk_by_paragraphs(text):\n","    paragraphs = text.split(\"\\n\\n\") # Assuming paragraphs are separated by two newlines\n","    return [p.strip() for p in paragraphs if p.strip()]\n","\n","chunks = chunk_by_paragraphs(pdf_text)\n","\n","# print(chunks[:1]) # Preview of the first 5 chunks"]},{"cell_type":"markdown","metadata":{},"source":["### Option 2: Chunking by Sentences\n","\n","If the document structure is more fluid and paragraphs are not clearly defined, you could break the text into sentences. You can use _nltk_ or a similar library for sentence tokennization"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"a5e90117-3793-4727-b22b-2f3814df300b","msg_id":"46f314d1-0ae3-4aae-bb37-27b88c780f7c"},"outputs":[],"source":["# import nltk\n","\n","# nltk.download('punkt')\n","\n","# def chunk_by_sentence(text):\n","#     sentences = nltk.sent_tokenize(text)\n","#     return sentences\n","\n","# chunks = chunk_by_sentence(pdf_text)\n","\n","# print(chunks[:5]) # Preview of the first 5 chunks"]},{"cell_type":"markdown","metadata":{},"source":["### Option 3: Chunking by Token length\n","\n","For more control over the chunk size, you can spilt the text into chunks of a fixed number of tokens"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ff585cc7-db9c-4af2-96a8-0628b6eb16d6","msg_id":"851c3e41-5f92-4c66-8e24-d3c18f57ffe5"},"outputs":[],"source":["def chunk_by_tokens(text, max_tokens=512):\n","    tokens = text.split() # Tokenize the whitespace\n","    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n","    return [' '.join(chunk) for chunk in chunks]\n","\n","chunks = chunk_by_tokens(pdf_text)\n","\n","# print(chunks[:1]) # Preview of the first 5 chunks"]},{"cell_type":"markdown","metadata":{},"source":["# Step 3: Embedding Generation"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"b9a699c2-e297-4b58-8c67-760f0d5340b3","msg_id":"d256c025-bd31-4bcb-939a-9c322798aed1"},"outputs":[{"data":{"text/plain":["<bound method Agent.list_connections of <ibm_watson_studio_lib.impl.agent.Agent object at 0x7f0452092cd0>>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["wslib.list_connections"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4967f991-b017-460e-a2df-916dce49b94f","msg_id":"fd9eb7fe-6b20-4d6e-8060-7cd910a15913"},"outputs":[{"name":"stdout","output_type":"stream","text":["6c0c63ab-ecd7-45bd-bea8-c4d2d6fe976a.cie9nt2d0bngcm5pd3og.lakehouse.dev.appdomain.cloud\n"]}],"source":["# note if you named your Milvus connection something other than \"Milvus Connection\" Please replace the name below\n","\n","milvus_credentials = wslib.get_connection(\"custom-service\")\n","print(milvus_credentials['host'])\n","# replace the milvus connection asset in the project"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"73ec2be5-caa9-4102-813d-072cd5186489","msg_id":"54cdbe70-1f01-400f-8c25-77e53d73fb4a"},"outputs":[],"source":["#milvus_credentials"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"f0aad8eb-08e6-49ef-b868-44d0f246525f","msg_id":"9f2884d1-a321-4c47-90e3-f00d189fff4b"},"outputs":[],"source":["from pymilvus import(\n","    Milvus,\n","    IndexType,\n","    Status,\n","    connections,\n","    FieldSchema,\n","    DataType,\n","    Collection,\n","    CollectionSchema,\n",")\n","\n","\n","url = milvus_credentials['host']\n","port = milvus_credentials['port']\n","apikey = milvus_credentials['password']\n","apiuser = 'ibmlhapikey'\n","\n","\n","connections.connect(alias=\"default\", \n","                    host=url, \n","                    port=port, \n","                    user=apiuser, \n","                    password=apikey, \n","                    secure=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"d2dae158-da1b-433a-bc74-0ab4249cf879","msg_id":"3984f5ec-34e9-419a-bff1-bcaed24c36fb"},"outputs":[],"source":["# Create a new collection\n","collection_description = 'wxd docs pdf'\n","collection_name = 'wxd_documentation2'"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9aa62853-7fb8-43c6-be9e-f6480ec4b265","msg_id":"f63dc3d1-547a-4ae4-b1c3-0d4e01cdbc22"},"outputs":[{"data":{"text/plain":["Status(code=0, message=)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Create collection - define fields + schema\n","\n","fields = [\n","    FieldSchema(name=\"document_id\", dtype=DataType.INT64), # Document Id\n","    FieldSchema(name=\"chunk_id\",  dtype=DataType.VARCHAR, is_primary=True, max_length=20000), # Chunk Id\n","    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384), # embedding dimension\n","]\n","\n","# Create a schema\n","schema = CollectionSchema(fields, collection_description)\n","\n","# Create a collection\n","collection = Collection(collection_name, schema)\n","\n","# Create index\n","index_params = {\n","        'metric_type':'L2',\n","        'index_type':\"IVF_FLAT\",\n","        'params':{\"nlist\":2048}\n","}\n","\n","collection.create_index(field_name=\"embedding\", index_params=index_params)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"7af099cb-7bc0-4ae2-90fb-284b7d9ce12e","msg_id":"60c7dcac-3254-47f4-9abd-f7c269372f12"},"outputs":[{"data":{"text/plain":["['wxd_documentation1',\n"," 'wxd_documentation2',\n"," 'test_collection',\n"," 'wxd_documentation']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# we can run a check to see the collections in our milvus instance and we see the new collection has been created \n","\n","from pymilvus import utility\n","utility.list_collections()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5c531cc4-56ec-4dcd-a61f-9cca82e963cb","msg_id":"2eee2c61-7133-424a-9c15-5cbfc26d2e00"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-12-17 20:01:08.582472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["len of chunks 302\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","wxd chunk: 'q' has been loaded.\n"]}],"source":["# load data into Milvus\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","from pymilvus import Collection, connections\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","data = []\n","print(\"len of chunks\", len(chunks))\n","model = SentenceTransformer('sentence-transformers/all-minilm-l12-v2') # 384 dim\n","\n","# for i in range(len(chunks)):\n","for i in range(10):\n","    # Create vector embeddings + data\n","    passage_embeddings = model.encode(chunks[i])\n","    document_id = i\n","    data.append({\"document_id\":document_id, \"chunk_id\":chunks[i],\"embedding\": passage_embeddings})\n","    print(i)\n","out = collection.insert(data)\n","    \n","print(\"wxd chunk: \\'\" + chunks[i][0] + \"\\' has been loaded.\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"d630914b-ec2a-47b9-92e0-d766c70a9a34","msg_id":"b14a6318-2555-4113-a41b-731e6127a8fe"},"outputs":[],"source":["## check to ensure entities have been loaded into the collection\n","\n","basic_collection = Collection(collection_name) \n","\n","basic_collection.num_entities\n","basic_collection.flush()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62512ec5-d1dc-4744-8eb1-aa1a34d14131"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Step 4: Searching with Milvus"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"a91053c4-296e-4f62-b4c6-d171b0b1eaaf","msg_id":"6d4c2d83-a4e3-45b5-a08b-68074b08cf11"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","from pymilvus import(\n","    Milvus,\n","    IndexType,\n","    Status,\n","    connections,\n","    FieldSchema,\n","    DataType,\n","    Collection,\n","    CollectionSchema,\n",")\n","\n","url = milvus_credentials['host']\n","port = milvus_credentials['port']\n","apikey = milvus_credentials['password']\n","apiuser = 'ibmlhapikey'\n","\n","\n","connections.connect(alias=\"default\", \n","                    host=url, \n","                    port=port, \n","                    user=apiuser, \n","                    password=apikey, \n","                    secure=True)\n","\n","\n","# Load collection\n","\n","basic_collection = Collection(collection_name)      \n","basic_collection.load()\n","\n","# Query function\n","def query_milvus(query, num_results):\n","    \n","    # Vectorize query\n","    model = SentenceTransformer('sentence-transformers/all-minilm-l12-v2') # 384 dim\n","    query_embeddings = model.encode([query])\n","\n","    # Search\n","    search_params = {\n","        \"metric_type\": \"L2\", \n","        \"params\": {\"nprobe\": 5}\n","    }\n","    results = basic_collection.search(\n","        data=query_embeddings, \n","        anns_field=\"embedding\", \n","        param=search_params,\n","        limit=num_results,\n","        expr=None, \n","        output_fields=['document_id'],\n","    )\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"d152a3f3-b1e8-4ee0-a004-18b4170bbe8e"},"source":["# Prompt with LLM"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"a91e98ee-61df-47ce-a8b0-a2c9061d52ac","msg_id":"87312e9f-0d21-44ae-992a-17793a49300a"},"outputs":[],"source":["## Consider some questions to ask regarding the topic you have chosen \n","\n","#question_text = \"OTHER QUESTION TEXT\"\n","\n","question_text = \"How to add a new catalog?\""]},{"cell_type":"code","execution_count":20,"metadata":{"id":"33a836e6-1a1d-4f1e-80f5-5808912d146d","msg_id":"c464ed25-f6d5-4535-940b-748f8753e2a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["['the left pane, go to Catalogs > All catalogs to view the available catalogs. 3. Select the catalog to open the catalog details page. 4. Click the catalog name and go to the Access control tab. 5. Go to Add collaborators > Add user and select a user role (Admin, Editor, or Viewer). 6. Search and select one or more users from the list and click Add. The user addition is successful. 7. Go to the Assets tab of the catalog details page, click the asset name, and go to the Access tab of the asset. 8. Click Add members, search for the added user, and click Add. Changing the owner of the asset Procedure 1. Go to the Assets tab of the catalog details page, click the asset name to open the asset details. 2. Click on the edit icon beside Asset owner and select a new user from the list. 3. Click, Apply. The asset owner is changed. Configure IBM Knowledge Catalog Do the following steps to associate a user to the table asset in IKC and assign the ownership. Procedure 1. Login to the IKC Cloud Pack for Data instance by using admin credentials. 2. From the watsonx.data home page, go to Access control. 3. Go to the Integration tab and click Integrate service. 4. Enter the following details: Field Description Service Select IBM Knowledge Catalog. 418 IBM watsonx.data: Release V2.0.0 Field Description Bucket catalog Select the applicable bucket catalogs for IKC governance. WKC endpoint Enter the IKC endpoint URL. API key Enter the Zen API key. For more information, see Generating API keys for authentication. 5. Click Integrate. The IKC integration is successful. Supported data types for IBM Knowledge Catalog Integration IBM Knowledge Catalog Integration with watsonx.data supports the following data types for transformation and masking. watsonx.data on Red Hat OpenShift • Varchar • Bigint • Boolean • Date • Double • Integer • Smallint • Timestamp • Tinyint Chapter 8. Integrations 419 Chapter 9. Working with Spark You can use watsonx.data to seamlessly integrate with Spark engine to achieve the following use cases: watsonx.data on Red Hat OpenShift • Ingesting large volumes of data into watsonx.data tables. Note: You can also cleanse and transform data before ingestion. • Table maintenance operations to enhance performance. • Complex analytics workloads that are difficult to represent as queries. External Spark engines External Spark engines are engines that exist in a different environment from where watsonx.data is deployed. You can deploy them in the following environments. watsonx.data on Red Hat OpenShift • Spark instance on Cloud • Spark on Cloud Pak for Data • Spark on EMR Based on the environment where the Spark engine is deployed, select the respective section to connect to watsonx.data: Working with Spark on Cloud Integrate watsonx.data with Analytics Engine serverless instance (Spark on Cloud) and run your Spark workloads. watsonx.data on Red Hat OpenShift Before you begin • Install IBM watsonx.data and ensure that the instance is up and running. For more information, see Installing watsonx.data on Red Hat OpenShift. • Provision an IBM Analytics', 'catalog. c) Click Save and restart engine. 2. Associate a catalog with an engine in topology view. a) Hover over the catalog that you want to associate with an engine and click the Manage associations icon. Chapter 5. Configuring user interface (UI) components 273 b) In Manage associations window, select the engine with which you want to associate the catalog. c) Click Save and restart engine. Exploring the catalog objects To explore the objects in a catalog, use one of the following methods: watsonx.data Developer edition watsonx.data on Red Hat OpenShift Procedure 1. Explore the catalog objects in list view. a) Click the name of catalog that you want to explore. Catalog information window opens. b) Click Objects. 2. Explore the catalog objects in topology view. a) Click the catalog that you want to explore. Catalog information window opens. b) Click Objects. Dissociating a catalog from an engine To dissociate a catalog with an engine, use one of the following methods: watsonx.data Developer edition watsonx.data on Red Hat OpenShift Procedure 1. Dissociate a catalog from an engine in list view. a) Click the overflow menu icon and then click Manage associations. b) In Manage associations window, clear the checkbox in the Engine column. c) Click Save and restart engine. 2. Dissociate a catalog from an engine in topology view. a) Hover over the catalog that you want to dissociate from an engine and click the Manage associations icon. b) In Manage associations window, clear the checkbox in the Engine column. c) Click Save and restart engine. Deleting an engine To delete an engine, use one of the following methods: watsonx.data on Red Hat OpenShift Procedure 1. Delete an engine in list view. a) Click the overflow menu icon at the end of the row and click Delete. A delete confirmation dialog appears. b) Click Delete. 2. Deleting a database in topology view. 274 IBM watsonx.data: Release V2.0.0 a) Hover over the engine that you want to delete and click the Delete icon. A delete confirmation dialog appears. b) Click Delete. Managing the Spark engine details IBM watsonx.data allows you to view and edit the details of a Spark engine. You can also monitor the status of the applications that are submitted in the instance. watsonx.data on Red Hat OpenShift About this task Viewing Spark details You can view the Spark details in list and topology views. 1. Click the name of Spark engine (either from list or topology view). Engine information window opens. 2. In the Details tab, you can view the following details: Field Description Display name The Spark engine name. Engine ID The unique identifier of the Spark instance. Description The description of the engine. Tags The tag that is specified at the time of registering an engine. Type The engine type. Here, IBM Analytics Engine (Spark). Instance URL The IBM Analytics Engine (Spark) URL. watsonx.data application endpoint The application submission endpoint. To submit an application by using API, see API Docs. Instance API endpoint The IBM Analytics Engine (Spark) API endpoint. History server endpoint The IBM Analytics Engine (Spark)', 'name. 7. Select all the data present on the bucket to sync or create a catalog without any preexisting data. 8. After registration, click the catalog and go to Sync logs. You can see the status of synchronization (success, failure, partial success) and the last sync time. 9. After completing the synchronization, go to the Data manager. You can see the catalog that you created and the tables that are pulled from the bucket created by Snowflake. Note: You can use SQL editor (Query workspace) and use these tables to select query and insert data into existing table. 10. If Snowflake user makes data changes in the bucket and watsonx.data wants to pull those changes in the bucket, then click Sync data from UI for three strategy options: 402 IBM watsonx.data: Release V2.0.0 a. Sync all data: Synchronize all the data or update the existing table that was promoted earlier. b. Sync new data only: Pull the newly created table only. c. Sync existing data only: Update the table registered earlier to the latest changes only. Chapter 6. Working with data 403 Chapter 7. Connecting to a Presto server Presto CLI provides a terminal-based interactive shell to run queries. You can connect to Presto server either through Presto CLI installed as part of the ibm-lh-client package or through Presto CLI installed separately. watsonx.data on Red Hat OpenShift To connect to a Presto Server from a client program or CLI, the following items are required: • Hostname and port for the Presto server or workstation where the IBM watsonx.data developer or stand-alone is installed. • Certificates served by the Presto server to establish trust. • Authorized user credentials to access the Presto server. Note: It is important to connect to the Presto server that uses its hostname and not its IP address. Because the TLS certificate that is served by the Presto Server is associated with a fully qualified host and domain-name (FQDN). Client programs, typically, cannot establish trust by using the IP address. With OpenShift Ingress in particular, DNS entries, based on hostnames, play an important role in routing to the intended Kubernetes Service. Tip: To confirm there is network access from your client workstation that needs to connect a Presto server you can test the access by using one of the following commands: curl -ki https://<presto-hostname>:<presto-portnumber> nc -v <presto-hostname> <presto-portnumber> • The Presto server exposes a HTTPs (TCP) port. Therefore, you can use any convenient HTTP or TCP- based utility to ensure that the Presto server can be accessed from your network. • When you run the curl command, the server may return HTTP/1.1 401 Unauthorized response. This is expected as the server is secured by authentication. • When you run the nc command, the server returns a success message. In watsonx.data, you can connect to the Presto server in multiple ways based on the platform and utilities you are using. See the following sections for more details: • Using built-in presto-cli in the developer edition • Using presto-cli and presto-run in the ibm-lh-client package • Using presto-cli executable (remote) –']\n"]}],"source":["# Query Milvus \n","\n","num_results = 3\n","results = query_milvus(question_text, num_results)\n","\n","relevant_chunks = []\n","for i in range(num_results):    \n","    text = results[0][i].id\n","    relevant_chunks.append(text)\n","    \n","print(relevant_chunks)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"85a0ccc0-43ef-4976-be3b-87a99a34f9be","msg_id":"29346ac7-261a-424e-b8ad-3c3f27840772"},"outputs":[{"name":"stdout","output_type":"stream","text":["the left pane, go to Catalogs > All catalogs to view the available catalogs. 3. Select the catalog to open the catalog details page. 4. Click the catalog name and go to the Access control tab. 5. Go to Add collaborators > Add user and select a user role (Admin, Editor, or Viewer). 6. Search and select one or more users from the list and click Add. The user addition is successful. 7. Go to the Assets tab of the catalog details page, click the asset name, and go to the Access tab of the asset. 8. Click Add members, search for the added user, and click Add. Changing the owner of the asset Procedure 1. Go to the Assets tab of the catalog details page, click the asset name to open the asset details. 2. Click on the edit icon beside Asset owner and select a new user from the list. 3. Click, Apply. The asset owner is changed. Configure IBM Knowledge Catalog Do the following steps to associate a user to the table asset in IKC and assign the ownership. Procedure 1. Login to the IKC Cloud Pack for Data instance by using admin credentials. 2. From the watsonx.data home page, go to Access control. 3. Go to the Integration tab and click Integrate service. 4. Enter the following details: Field Description Service Select IBM Knowledge Catalog. 418 IBM watsonx.data: Release V2.0.0 Field Description Bucket catalog Select the applicable bucket catalogs for IKC governance. WKC endpoint Enter the IKC endpoint URL. API key Enter the Zen API key. For more information, see Generating API keys for authentication. 5. Click Integrate. The IKC integration is successful. Supported data types for IBM Knowledge Catalog Integration IBM Knowledge Catalog Integration with watsonx.data supports the following data types for transformation and masking. watsonx.data on Red Hat OpenShift • Varchar • Bigint • Boolean • Date • Double • Integer • Smallint • Timestamp • Tinyint Chapter 8. Integrations 419 Chapter 9. Working with Spark You can use watsonx.data to seamlessly integrate with Spark engine to achieve the following use cases: watsonx.data on Red Hat OpenShift • Ingesting large volumes of data into watsonx.data tables. Note: You can also cleanse and transform data before ingestion. • Table maintenance operations to enhance performance. • Complex analytics workloads that are difficult to represent as queries. External Spark engines External Spark engines are engines that exist in a different environment from where watsonx.data is deployed. You can deploy them in the following environments. watsonx.data on Red Hat OpenShift • Spark instance on Cloud • Spark on Cloud Pak for Data • Spark on EMR Based on the environment where the Spark engine is deployed, select the respective section to connect to watsonx.data: Working with Spark on Cloud Integrate watsonx.data with Analytics Engine serverless instance (Spark on Cloud) and run your Spark workloads. watsonx.data on Red Hat OpenShift Before you begin • Install IBM watsonx.data and ensure that the instance is up and running. For more information, see Installing watsonx.data on Red Hat OpenShift. • Provision an IBM Analytics\n","\n","catalog. c) Click Save and restart engine. 2. Associate a catalog with an engine in topology view. a) Hover over the catalog that you want to associate with an engine and click the Manage associations icon. Chapter 5. Configuring user interface (UI) components 273 b) In Manage associations window, select the engine with which you want to associate the catalog. c) Click Save and restart engine. Exploring the catalog objects To explore the objects in a catalog, use one of the following methods: watsonx.data Developer edition watsonx.data on Red Hat OpenShift Procedure 1. Explore the catalog objects in list view. a) Click the name of catalog that you want to explore. Catalog information window opens. b) Click Objects. 2. Explore the catalog objects in topology view. a) Click the catalog that you want to explore. Catalog information window opens. b) Click Objects. Dissociating a catalog from an engine To dissociate a catalog with an engine, use one of the following methods: watsonx.data Developer edition watsonx.data on Red Hat OpenShift Procedure 1. Dissociate a catalog from an engine in list view. a) Click the overflow menu icon and then click Manage associations. b) In Manage associations window, clear the checkbox in the Engine column. c) Click Save and restart engine. 2. Dissociate a catalog from an engine in topology view. a) Hover over the catalog that you want to dissociate from an engine and click the Manage associations icon. b) In Manage associations window, clear the checkbox in the Engine column. c) Click Save and restart engine. Deleting an engine To delete an engine, use one of the following methods: watsonx.data on Red Hat OpenShift Procedure 1. Delete an engine in list view. a) Click the overflow menu icon at the end of the row and click Delete. A delete confirmation dialog appears. b) Click Delete. 2. Deleting a database in topology view. 274 IBM watsonx.data: Release V2.0.0 a) Hover over the engine that you want to delete and click the Delete icon. A delete confirmation dialog appears. b) Click Delete. Managing the Spark engine details IBM watsonx.data allows you to view and edit the details of a Spark engine. You can also monitor the status of the applications that are submitted in the instance. watsonx.data on Red Hat OpenShift About this task Viewing Spark details You can view the Spark details in list and topology views. 1. Click the name of Spark engine (either from list or topology view). Engine information window opens. 2. In the Details tab, you can view the following details: Field Description Display name The Spark engine name. Engine ID The unique identifier of the Spark instance. Description The description of the engine. Tags The tag that is specified at the time of registering an engine. Type The engine type. Here, IBM Analytics Engine (Spark). Instance URL The IBM Analytics Engine (Spark) URL. watsonx.data application endpoint The application submission endpoint. To submit an application by using API, see API Docs. Instance API endpoint The IBM Analytics Engine (Spark) API endpoint. History server endpoint The IBM Analytics Engine (Spark)\n","\n","name. 7. Select all the data present on the bucket to sync or create a catalog without any preexisting data. 8. After registration, click the catalog and go to Sync logs. You can see the status of synchronization (success, failure, partial success) and the last sync time. 9. After completing the synchronization, go to the Data manager. You can see the catalog that you created and the tables that are pulled from the bucket created by Snowflake. Note: You can use SQL editor (Query workspace) and use these tables to select query and insert data into existing table. 10. If Snowflake user makes data changes in the bucket and watsonx.data wants to pull those changes in the bucket, then click Sync data from UI for three strategy options: 402 IBM watsonx.data: Release V2.0.0 a. Sync all data: Synchronize all the data or update the existing table that was promoted earlier. b. Sync new data only: Pull the newly created table only. c. Sync existing data only: Update the table registered earlier to the latest changes only. Chapter 6. Working with data 403 Chapter 7. Connecting to a Presto server Presto CLI provides a terminal-based interactive shell to run queries. You can connect to Presto server either through Presto CLI installed as part of the ibm-lh-client package or through Presto CLI installed separately. watsonx.data on Red Hat OpenShift To connect to a Presto Server from a client program or CLI, the following items are required: • Hostname and port for the Presto server or workstation where the IBM watsonx.data developer or stand-alone is installed. • Certificates served by the Presto server to establish trust. • Authorized user credentials to access the Presto server. Note: It is important to connect to the Presto server that uses its hostname and not its IP address. Because the TLS certificate that is served by the Presto Server is associated with a fully qualified host and domain-name (FQDN). Client programs, typically, cannot establish trust by using the IP address. With OpenShift Ingress in particular, DNS entries, based on hostnames, play an important role in routing to the intended Kubernetes Service. Tip: To confirm there is network access from your client workstation that needs to connect a Presto server you can test the access by using one of the following commands: curl -ki https://<presto-hostname>:<presto-portnumber> nc -v <presto-hostname> <presto-portnumber> • The Presto server exposes a HTTPs (TCP) port. Therefore, you can use any convenient HTTP or TCP- based utility to ensure that the Presto server can be accessed from your network. • When you run the curl command, the server may return HTTP/1.1 401 Unauthorized response. This is expected as the server is secured by authentication. • When you run the nc command, the server returns a success message. In watsonx.data, you can connect to the Presto server in multiple ways based on the platform and utilities you are using. See the following sections for more details: • Using built-in presto-cli in the developer edition • Using presto-cli and presto-run in the ibm-lh-client package • Using presto-cli executable (remote) –\n","\n","Please answer a question using this text. If the question is unanswerable, say \"unanswerable\".\n","\n","Question: How to add a new catalog?\n"]}],"source":["def make_prompt(context, question_text):\n","    return (f\"{context}\\n\\nPlease answer a question using this text. \"\n","          + f\"If the question is unanswerable, say \\\"unanswerable\\\".\"\n","          + f\"\\n\\nQuestion: {question_text}\")\n","\n","\n","# Build prompt w/ Milvus results\n","# Embed retrieved passages(context) and user question into into prompt text\n","\n","context = \"\\n\\n\".join(relevant_chunks)\n","prompt = make_prompt(context, question_text)\n","\n","print(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.11 with Spark","language":"python3","name":"python311"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
